{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import *\n",
    "from keras.engine.topology import Container\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.losses import *\n",
    "from keras.optimizers import *\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from functools import reduce\n",
    "from tqdm import tqdm_notebook\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from matplotlib import pylab as plt\n",
    "from IPython.display import clear_output\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "import pickle\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./parsed.txt\", \"r\") as f:\n",
    "    texts = f.read().split(\"\\n\")\n",
    "tokenizer = Tokenizer(filters=\"\\n\", lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(texts)\n",
    "VOCAB = len(tokenizer.word_index)\n",
    "X = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InvTokenizer:\n",
    "    def __init__(self, dic):\n",
    "        self.dic = dic\n",
    "        self.num = len(dic)\n",
    "        self.invdec = [\"\" for _ in range(self.num + 1)]\n",
    "        for c, i in self.dic.items():\n",
    "            self.invdec[i] = c\n",
    "    \n",
    "    def __call__(self, array):\n",
    "        if len(array) == 0: return(\"\")\n",
    "        return(reduce(lambda x,y:x+y,[self.invdec[int(i)] for i in list(array)]))\n",
    "            \n",
    "texgen = InvTokenizer(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_softmax(y, tau):\n",
    "    return(np.exp(y/tau)/np.exp(y/tau).sum())\n",
    "    \n",
    "def get_model():\n",
    "    inputs = Input(shape=(None,))\n",
    "    y = inputs\n",
    "    y = Embedding(VOCAB+1, 512, mask_zero=True)(y)\n",
    "    y = Dropout(0.1)(y)\n",
    "    y = GRU(512, return_sequences=True, recurrent_dropout=0.1)(y)\n",
    "    y = Dropout(0.1)(y)\n",
    "    y = GRU(512, return_sequences=True, recurrent_dropout=0.1)(y)\n",
    "    y = Dropout(0.1)(y)\n",
    "    y = TimeDistributed(Dense(VOCAB+1, activation=\"softmax\", use_bias=False))(y)\n",
    "    model = Model(inputs, y)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=RMSprop(1e-3))\n",
    "    return(model)\n",
    "\n",
    "def datagen(X, batch_size=128):\n",
    "    x, y = [], []\n",
    "    np.random.shuffle(X)\n",
    "    for text in tqdm_notebook(X):\n",
    "        x.append(text[:-1])\n",
    "        y.append(text[1:])\n",
    "        if len(y) >= batch_size:\n",
    "            x = pad_sequences(np.array(x), maxlen=TEXT_LENGTH, padding=\"post\")\n",
    "            y = pad_sequences(y, maxlen=TEXT_LENGTH, padding=\"post\")\n",
    "            y = np.expand_dims(np.array(y), -1)\n",
    "            yield(x, y)\n",
    "            x, y = [], []\n",
    "\n",
    "def get_text(mod, tau=1.0):\n",
    "    TEXT_MIN = 20\n",
    "    x = [[tokenizer.word_index[\"@SOS\"]]]\n",
    "    while len(x[0]) < TEXT_LENGTH:\n",
    "        y = mod.predict(np.array(x))[0][-1]\n",
    "        y = np.log(y)\n",
    "        y = temperature_softmax(y, tau)\n",
    "        y = np.random.choice(VOCAB+1, p=y)\n",
    "        if y == 1:\n",
    "            return(texgen(x[0][1:]))\n",
    "        x[0].append(y)\n",
    "    return(texgen(x[0][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = get_model()\n",
    "mod.summary()\n",
    "mod.load_weights(\"./auto_twitter_2.h5\")\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "batch_size = 200\n",
    "mod.optimizer = Adam()\n",
    "for e in range(epoch):\n",
    "    gen = datagen(X, batch_size=batch_size)\n",
    "    for x, y in BackgroundGenerator(gen):\n",
    "        loss = mod.train_on_batch(x, y)\n",
    "        history.append(loss)\n",
    "    clear_output()\n",
    "    plt.plot(history)\n",
    "    plt.show()\n",
    "    print(get_text(mod))\n",
    "    mod.save(filepath=\"./auto_twitter_2.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join([get_text(mod, tau=1.5) for _ in range(20)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
